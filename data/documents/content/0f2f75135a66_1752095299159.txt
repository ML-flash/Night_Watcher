In 2019, a California man made a small typo in a tax document, sending his refund check to a complete stranger. According to the ABC affiliate reporting the story, the Internal Revenue Service (IRS) recognized the error but not California’s financial agency, leaving the man unable to recover his money.
Imagine if that error, and the many problems caused by similar errors in government forms, could be avoided by intelligent software that excels in routine tasks. Modern generative artificial intelligence (Gen AI), such as ChatGPT, can automate routine tasks and spot errors, saving citizens from costly mistakes and agencies from mounting administrative burdens. Indeed, OpenAI recently released ChatGPT Gov, which aims to help government agencies leverage this new technology.
Federal agencies should be directed to explore integrating artificial intelligence (AI) into their own processes.
The explosive growth in productivity seen by businesses utilizing AI could likewise streamline citizen interactions with the government and reduce staffing overhead that deals with unnecessary bureaucratic complications.
President Trump’s Department on Government Efficiency (DOGE) has been slashing government expenses and workers to the chagrin of many congressional Democrats. While this issue of government efficiency was a partisan message during the 2024 presidential campaign, there is an opportunity to leverage brand-new AI technologies to solve bureaucratic shortcomings that have long been a bipartisan goal. For example, one of President Obama’s early initiatives was a waste-cutting program.
In addition to the impacts on the public sector, increased government use of AI could also lead to a more collaborative approach to regulation with the technology industry.
Government agencies utilizing AI systems could set global standards for how software developers comply with the growing web of safety regulations popping up in different states and countries.
While there are relatively few companies with enough resources to develop their own models, such as Google and OpenAI, it can cost no more than a few dollars to slightly modify or “fine-tune” a foundational model based on a specific dataset for a particular use case. The EU AI Act, and similar U.S. state proposals, require complex legal compliance to ensure AI models, including fine-tuned modifications, are not abused for nefarious purposes.
Importantly, these rules apply to governments as well as the private sector.
By developing frameworks for compliance with state and international AI standards, governments would have a stronger incentive to understand how to perform legal compliance on the very regulations that they may be proposing for the private sector, leading to greater collaboration between technologists and agencies.
Moreover, these agencies, and their partners in academia and nonprofits, are ideally aligned to tackle thorny issues such as cyber security, privacy, worker rights, and discrimination—all while improving vital services for citizens.
When government staff develop their own AI use cases, they both help set ethical standards while saving industry legal costs thanks to freely available templates for compliance.
There are a few possible approaches to integrating AI into government.
Public-private partnerships for AI pilots
Legislation could direct select agencies to pilot AI-powered systems to automate routine paperwork processes, such as licensing and benefit applications.
Indeed, California is piloting a project to partner with private companies to test generative AI solutions to operational issues using the state’s open data. California’s Department of Tax and Fee Administration reportedly plans an AI program for its call centers.
Agencies can also establish standards to protect consumer privacy and financial records when using AI to process tax documents.
Release data for private sector development
Data is a critical ingredient in AI development, because machine learning models need successful examples to learn how to create new content or identify mistakes.
There are many examples of non-sensitive applications that the government could simply release in bulk. For instance, back in September 2024, I made a records request to the Colorado Department of Regulatory Affairs (DORA) related to schools applying for certification to train professionals under a new mental health program. There was no personally identifying information in these applications. It was mostly curricular details, like books and lesson plans, but highly structured in a legally complex way to comply with the state’s application guidelines.
It is common for states to keep a record of schools and professionals in health care fields who maintain an active credential.
However, the application process for organizational and occupational licensing is quite burdensome; it is expensive and time-consuming for consumers to construct an application; it is costly for agencies to manually go over all the paperwork and answer questions. This ultimately ends up costing consumers more money for health care, since agencies charge fees to pay for staff to process applications, and providers pass on the costs of fees to consumers.
After reviewing the applications, I found that they were all quite similar. An AI model could easily help professionals fill out the paperwork and agency staff check for common errors. In cases where paperwork contains sensitive information, many states have existing standards about how to protect personally identifiable information when releasing public records.
These are just a few examples of how government agencies could explore the integration of artificial intelligence. Ultimately, if implemented responsibly, AI has the potential to make government operations faster, leaner, and more citizen friendly.
-
Acknowledgements and disclosures
Google is a general, unrestricted donors to the Brookings Institution. The findings, interpretations, and conclusions posted in this piece are solely those of the authors and are not influenced by any donation.
The Brookings Institution is committed to quality, independence, and impact.
We are supported by a diverse array of funders. In line with our values and policies, each Brookings publication represents the sole views of its author(s).
You log into [insert social media platform of choice], in the mood for the latest news, your friends' baby pics, a few outlandish opinions. But have you considered what the state commissioner of mental hygiene has to say about that?
If lawmakers in New York and Minnesota get their way, social media users will be greeted with persistent warnings about the potential toll their scrolling habits could be taking on their mental health.
Legislatures in both states recently passed legislation requiring warning labels on social media, despite an utter lack of evidence that this will do good and one federal court ruling declaring a similar law for porn websites to be unconstitutional.
You are reading Sex & Tech, from Elizabeth Nolan Brown. Get more of Elizabeth's sex, tech, bodily autonomy, law, and online culture coverage.
The Minnesota rule says a "conspicuous mental health warning label" must appear each time a user accesses a social media platform and only disappear when the user exits the platform or "acknowledges the potential for harm and chooses to proceed to the social media platform despite the risk." It came as part of a larger bill signed by Gov. Tim Walz in June.
The New York bill—which passed both houses of the state Legislature but is still awaiting Gov. Kathy Hochul's signature—mandates that any social media platform that provides the basic features we've come to expect (like autoplay, infinite scroll, push notifications, or like counts) must display a warning label "prescribed by the commissioner of mental hygiene."
This is peak performative lawmaking. It lets state lawmakers pretend to be doing something to save us from the boogeyman du jour, Big Tech. They can put out their press releases and pat themselves on their backs.
Check out the gag-inducingly grandiose tone in which New York state Sen. Andrew Gounardes has been talking about the measure he sponsored. "This is about enabling New Yorkers to reclaim control of their own lives from big corporations," Gounardes said … as if people can't currently just stop or reduce social media use but will somehow miraculously gain this power when they see some government-mandated legalese about tech addiction above their feeds.
In the real world, government goons telling you to put down Instagram and go touch grass would be unlikely to help even if it could pass constitutional muster—which it almost certainly won't.
"You'd think lawmakers would learn," writes Mike Masnick at Techdirt:
When Texas passed a ridiculous law requiring adult websites to add "health warning labels" based on no science at all, even the notoriously ridiculous Fifth Circuit—a court that never met a garbage internet law it didn't like—said "whoa, the mandated health warning part's obviously unconstitutional." The court explained that compelling websites to display the state's preferred message about content when there's no scientific consensus is completely out of line. […] But apparently, NY and Minnesota lawmakers saw that ruling and thought: "Let's do the exact same thing, but for social media!"
Both the New York law and the Minnesota law represent the government trying to compel speech in an impermissible way.
"The Supreme Court has established through cases like Zauderer that the government can only compel commercial speech (like warning labels) when the compelled disclosure is 'purely factual and uncontroversial' and relates to preventing consumer deception," notes Masnick. "Neither condition applies here."
Pittsburgh Lowers Sex Work Penalty
The Pittsburgh City Council voted last night to reduce penalties for prostitution. Under the newly passed ordinance, police can choose to essentially issue a citation rather than arrest someone for a misdemeanor crime.
As it stands, the minimum penalty for engaging in prostitution "can involve up to a year in jail, and it also can involve a sliding scale of fines that can go all the way up to $10,000," Theresa Nightingale, executive director of For Safer Sex Work Pittsburgh, told the Pittsburgh City Paper. Under the new ordinance, someone engaging in prostitution in Pittsburgh could receive "just a small fine similar to a traffic ticket," she said.
Pittsburgh Councilwoman Barb Warwick, who introduced the legislation, said at a council meeting last week that she would "love if we could legalize consensual sex work but we cannot in the city. That would be a state issue. This is just about the penalty, very similar to the change in penalty for cannabis possession."
Pennsylvania's state law on prostitution remains unchanged. And Pittsburgh authorities can still charge sex workers with violating that law—a misdemeanor offense.
But under the new ordinance, they can also choose to merely charge them with the summary offense of engaging in prostitution, which means no court appointments, no jail time, and a punishment consisting of either a fine of up to $100 or up to 20 hours of community service.
Decriminalizing selling sex altogether would be a more just solution. Under this new scheme, people will at best still face some punishment for engaging in consensual commercial sex and could still be arrested and prosecuted on criminal charges. But as Warwick pointed out, changing state law doesn't fall under the city council's purview.
What Warwick and other city council members have done here represents one way city lawmakers actually have the power to reduce the impact of laws criminalizing prostitution. It might not be perfect, but it's a step—the sort of thing that helped get the ball rolling with marijuana legalization. It serves as a good reminder that the battle over sex work laws isn't an all-or-nothing proposition. And for those directly impacted by criminalization, it could be a significantly positive change.
"As a trans woman who has done sex work before and not had 25 to 100 dollars in my bank account at all times, going to [Allegheny County Jail], which is notorious for the torture of trans women, is torture as punishment for trying to work," Alexandra Weiner told the Pittsburgh City Paper. "The ordinance, while just a start, removes the existential threat of carceral violence from hanging over our heads."
Catching Up: FSC v. Paxton, Anthropic, the Diddy Trial
I was on two family vacations and two work trips between the beginning of June and the beginning of this week, so that's why this newsletter has been absent from your inbox as of late. I know I've missed some major stories on the sex and tech beats, including the Supreme Court's decision in Free Speech Coalition v. Paxton (in which it held that "the power to require age verification is within a State's authority to prevent children from accessing sexually explicit content" online), a federal court ruling that Anthropic didn't violate copyright law by training its large language model on copyrighted books, and a ruling in the federal criminal case against Sean "Diddy" Combs. On the first and the last of these, I want to offer just a smidge of brief, belated comment.
On porn platforms and age verification: The Supreme Court ruling is obviously disappointing—and, beyond that, a bit baffling. As Jess Miers notes in this great thread, Justice Clarence Thomas acknowledges that "adults have the right to access speech that is obscene only to minors" and that "submitting to age verification is a burden on the exercise of that right." But Thomas goes on to assert that, somehow, this doesn't matter and "adults have no First Amendment right to avoid age verification."
"The upshot of Thomas' opinion is that the First Amendment rights of adults have been watered down," my colleague Damon Root wrote.
"Typically, laws that conceivably burden the First Amendment are subjected to strict scrutiny by the courts, which is the most exacting level of judicial review," Root explained. "Under strict scrutiny, the government must, first, prove that its law serves a compelling government interest, and, second, prove that the law is the least restrictive means available of advancing that interest. But Thomas opted instead for the less exacting level known as intermediate scrutiny. And, in so doing, he helped to ensure that the Texas law would survive judicial review."
The ruling is bound to have repercussions far beyond pornography regulation. "Americans will live to regret the day we let the government condition access to protected speech on proof of our identity," as the Foundation for Individual Rights and Expression put it.
This is gateway age verification; it's not going to stop with porn. (See, for example, Australia, which followed up on rules regarding age checks for porn websites with a requirement that Australians verify their ages "when surfing the web while logged into their Google or Microsoft accounts and using each company's respective search engines," as Mashable reports.)
On Sean Combs and sex trafficking: In a far different—but way more high-profile—recent court ruling, we've got the Mann Act rearing its absurd head again. Combs was acquitted on the more serious charges he faced—sex trafficking and racketeering—and convicted only on two counts of transporting someone across state lines for prostitution in violation of the Mann Act, a Victorian-era sex-panic law that federal prosecutors still love.
Some people are taking this decision as evidence that Combs was innocent of any sexual misconduct, while others are aghast that so many people accusing him of victimizing them would be disbelieved. But Combs was not on trial for rape or sexual assault. These are not federal crimes. There are separate, civil cases involving individual allegations of this sort. This case was about the Department of Justice trying to get in on a high-profile scandal with a sensational but ill-fitting case.
I criticized the federal charges when they were first revealed last fall—not because I believe that Combs is innocent of all sexual misconduct, but because the case seems to represent the feds (once again) trying to shoehorn everything into a sex trafficking case even when it doesn't make sense. The only charge prosecutors seemingly had a clear case on was the Mann Act charge, which revolved around Combs making "arrangements for women and [male] commercial sex workers to fly to [his] location." And that's the (rather benign) activity of which he ended up being convicted. The rest of the indictment detailed some allegations of violence, which would fall to state or local authorities to prosecute, and a lot of lurid details about sex parties and other scandalous activity. Nothing seemed to rise to the level of human trafficking unless we're radically redefining the statute (which, of course, the feds are always trying to do).
Some people will suggest that there's no harm in the DOJ trying. But setting aside for a moment the danger of letting FBI agents and prosecutors redefine laws—and that's a big danger—I think we should also consider the harm that this does to the civil cases here and to the chances of alleged victims being believed more generally. The DOJ slapped some sex-trafficking charges on Combs and failed because it was a bad case. But this will likely leave many casual observers with the impression that Combs is innocent of any allegations against him and that he was exonerated of all sexual misconduct. And every time a high-profile case against celebrities falls apart, people seem less inclined to believe the next one. So in trying to fit this case into federal authorities' pet framework—sex trafficking—they may have actually done a disservice to victims of violence and sexual abuse.
More Sex & Tech News
• Elon Musk's AI tool, Grok, has labeled itself MechaHitler and started making antisemitic comments after a recent revamp.
• The Reason Foundation's Max Gulker reports on misguided efforts to regulate the use of algorithms in approving rental applications—and the larger issue with calling everything algorithm-enabled "artificial intelligence." Computer algorithms "have been commonly used throughout housing markets for decades and are subject to existing anti-discrimination laws," notes Gulker. "What is new is calling these algorithms 'artificial intelligence' or 'AI.'" Legally speaking, this doesn't matter:
Whether SafeRent's algorithm employed a large language model or older programming technology does not impact whether it violated discrimination law. In general, there is no clear line between what we call AI today and many of the algorithms we have used for years without that moniker. It is not surprising that the big tent of what we call AI continues to grow. Companies want to use the term for branding purposes, just as the media does for headlines.
However, this rapid renaming of many algorithms as "AI" matters in the realm of policy. Both regulators and the public are willing to consider bolder and more sweeping regulation of AI than would be likely with more incremental technological change. Mainstream policy proposals for regulating AI have run the gamut from a somewhat fantastical moratorium on AI innovation itself to a moratorium on regulation at the state level. The technologies placed in the "AI" bucket may end up on a very different regulatory trajectory than those that don't.
• The Texas Observer looks at an investigation into famed and controversial photographer Sally Mann's pictures of her children—some of which involve nudity, and some of which are hanging in the Modern Art Museum of Fort Worth—and uses it as a jumping off point for examining if we're in a new era of heightened art and museum censorship. Whatever you think of the appropriateness or not of the (artistic and not sexually oriented) photos, they were first published (and controversial in) the 1990s, and it's patently absurd that they are once again stirring up not just comment (OK) but criminal investigation (not OK). "It remains unclear who or what pushed the Fort Worth Police Department (FWPD) to pursue an investigation with no clear precedent among successful criminal prosecutions," notes the Observer. "Since the photos were returned, an additional baffling detail has emerged: FWPD spent $7,000 on travel to New York City to investigate 'critical leads' pertaining to Mann's photos, which are already among the best-studied and most-discussed works in U.S. contemporary art."
• The law requiring TikTok parent company ByteDance to sell it or stop operating in the U.S. "is a bad law," but "leaving it on the books and willfully ignoring it sets a potentially more dangerous precedent about government power. If Congress is not going to repeal the law, then they should insist it be enforced," argues Reason's Joe Lancaster. What do you think?